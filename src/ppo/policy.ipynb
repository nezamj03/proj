{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import sys\n",
    "sys.path.append('/Users/nezamjazayeri/Documents/neu/cs5180/proj/src')\n",
    "\n",
    "from networks.mlp import MLP\n",
    "from utils.parse_config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config('config/default.yaml')\n",
    "num_players = config['env_args']['num_players']\n",
    "\n",
    "\n",
    "def generate(t, winner=False):\n",
    "\n",
    "    if t == 0:\n",
    "        return [0, num_players, 0, 0, 0]\n",
    "    res = [0, 0, 0, 0, 0]\n",
    "    res[0] = t\n",
    "    res[1] = max(num_players - (t * 4), 2)\n",
    "    res[2] = max(1, max(num_players - ((t - 1) * 4), 2) - 1)\n",
    "    res[3] = 0\n",
    "    if winner == True:\n",
    "        res[3] = 1\n",
    "    res[4] = 1\n",
    "    return res\n",
    "\n",
    "STATES = [\n",
    "    generate(0),\n",
    "    generate(1),\n",
    "    generate(2),\n",
    "    generate(3),\n",
    "    generate(4)\n",
    "]\n",
    "\n",
    "STATES_v2 = [\n",
    "    generate(0, winner=True),\n",
    "    generate(1, winner=True),\n",
    "    generate(2, winner=True),\n",
    "    generate(3, winner=True),\n",
    "    generate(4, winner=True)\n",
    "]\n",
    "\n",
    "state_size = 5\n",
    "action_size = 2\n",
    "\n",
    "model = MLP(state_size, action_size, config)\n",
    "load = config['total_train_t']\n",
    "path = f\"/Users/nezamjazayeri/Documents/neu/cs5180/proj/res/models/PPO/20240428/{load}/policy.pt\"\n",
    "model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def get_policy(state):\n",
    "    \n",
    "    with torch.no_grad():  # No gradient computation for action selection\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)  # Convert state to tensor and add batch dimension\n",
    "        logits = model(state)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "    print(f'@ round {int(state[0][0].item()) + 1}:',\n",
    "          f'q0= {probs[0][0].item()},',\n",
    "          f'q1= {probs[0][1].item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ round 1: q0= 0.17418237030506134, q1= 0.8258176445960999\n",
      "@ round 2: q0= 0.2386985570192337, q1= 0.7613014578819275\n",
      "@ round 3: q0= 0.24906538426876068, q1= 0.7509346008300781\n",
      "@ round 4: q0= 0.28186753392219543, q1= 0.7181324362754822\n",
      "@ round 5: q0= 0.3171650767326355, q1= 0.6828349232673645\n"
     ]
    }
   ],
   "source": [
    "for state in STATES:\n",
    "    get_policy(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
